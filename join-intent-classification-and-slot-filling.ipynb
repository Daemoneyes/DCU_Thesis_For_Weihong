{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Joint Intent Classification and Slot Filliing with Transformers\n\nCode get and modified from the Master Datascience Paris Saclay. [here](https://github.com/m2dsupsdlclass/lectures-labs).\n\n**Goal**\n* Fine-tune a pretrained transformer-based neural network model to convert a user qeury expressed in English into a representation that is structured enough to be processed by an automated service.\n\nHere is an example of interpretation computed by such a Natural Language Understanding system:\n    \n    >>> nlu('Book a table for two at Le Ritz for Friday night\",\n            tokenizer, joint_model, intent_names, slot_names)\n    {\n        'intent': 'BookRestaurant',\n        'slots': {\n            'party_size_number': 'two',\n            'restaurant_name': 'Le Ritz',\n            'timeRange': 'Friday night'\n        }\n    }\n    \nIntent classification is a simple classification problem. The trick is to treat the structured knowledge extraction part (\"Slot Filling\") as a token-level classification problem using BIO-annotations:\n\n    >>> show_predictions('Book a table for two at Le Ritz for Friday night',\n                         tokenizer, joint_model, intent_names, slot_names)\n    ## Intent: BookRestaurant\n    ## Slots:\n      Book : O\n         a : O\n     table : O\n       for : O\n       two : B-party_size_number\n        at : O\n        Le : B-restaurant_name\n         R : I-restaurant_name\n     ##itz : I-restaurant_name\n       for : O\n    Friday : B-timeRange\n     night : I-timeRange\n     \nWe will show hhow to train a such \"sequence classification\" and \"token classification\" joint model on a voice command dataset published by snips.ai. This notebook is a partial reproduction of some of the results presented in this paper: BERT for Joint Intent Classification and Shot Filling, Qian Chen, Zhu Zhuo, Wen Wang [link](https://arxiv.org/abs/1902.10909).","metadata":{}},{"cell_type":"code","source":"# Load packages\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nfrom pathlib import Path\nfrom transformers import BertTokenizer, TFBertModel,pipeline,AutoTokenizer\nfrom urllib.request import urlretrieve\n\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\nfrom tensorflow.keras.metrics import SparseCategoricalAccuracy\nfrom tensorflow.keras.optimizers import Adam\nimport tensorflow_hub as hub\n\nimport datetime\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-27T06:03:08.515735Z","iopub.execute_input":"2021-08-27T06:03:08.516164Z","iopub.status.idle":"2021-08-27T06:03:16.844006Z","shell.execute_reply.started":"2021-08-27T06:03:08.51612Z","shell.execute_reply":"2021-08-27T06:03:16.842914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\nsimilarModel = hub.load(module_url)\nprint (\"module %s loaded\" % module_url)\ndef embed(input):\n    return similarModel(input)\ntest_embed = embed([\"hello world\"])","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:03:16.846544Z","iopub.execute_input":"2021-08-27T06:03:16.846889Z","iopub.status.idle":"2021-08-27T06:03:51.195751Z","shell.execute_reply.started":"2021-08-27T06:03:16.846855Z","shell.execute_reply":"2021-08-27T06:03:51.194555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SNIPS_DATA_BASE_URL = (\n    \"https://github.com/ogrisel/slot_filling_and_intent_detection_of_SLU/blob/\"\n    \"master/data/MIT_corpus/restaurant/\"\n)\nfor filename in [\"train\", \"valid\", \"test\", \"vocab.intent\", \"vocab.slot\"]:\n    path = Path(filename)\n    if not path.exists():\n        print(f\"Downloading {filename}...\")\n        urlretrieve(SNIPS_DATA_BASE_URL + filename + \"?raw=true\", path)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:03:51.197693Z","iopub.execute_input":"2021-08-27T06:03:51.198174Z","iopub.status.idle":"2021-08-27T06:03:56.949063Z","shell.execute_reply.started":"2021-08-27T06:03:51.198129Z","shell.execute_reply":"2021-08-27T06:03:56.948121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's have a look at the first lines from the training set.","metadata":{}},{"cell_type":"code","source":"lines_train = Path('train').read_text('utf-8').strip().splitlines()","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:03:56.950893Z","iopub.execute_input":"2021-08-27T06:03:56.95137Z","iopub.status.idle":"2021-08-27T06:03:56.963237Z","shell.execute_reply.started":"2021-08-27T06:03:56.951322Z","shell.execute_reply":"2021-08-27T06:03:56.962183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'First line of training set: {lines_train[0]}.')","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:03:56.96882Z","iopub.execute_input":"2021-08-27T06:03:56.969151Z","iopub.status.idle":"2021-08-27T06:03:58.17085Z","shell.execute_reply.started":"2021-08-27T06:03:56.96912Z","shell.execute_reply":"2021-08-27T06:03:58.16927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some remarks:\n* The class label for the voice command appears at the end of each line (after the \"<=>\" marker).\n* Each word-level token is annotated with B-I-O labels using the \".\" separator.\n* B-I-O stands for Beginning-Inside-Outside\n* \"Add:O\" means that the token \"Add\" is \"Outside\" of any annotation span.\n* \"Don:B-entity_name\" means that \"Don\" is the \"Beginning\" of an annotation of type \"entity_name\".\n* \"and:I-entity_name\" means that \"and\" is \"inside\" the previously started annotation of type \"entity_name\".\n\nLet's write a parsing function and test it on the first line.","metadata":{}},{"cell_type":"code","source":"def parse_line(line):\n    utterance_data, intent_label = line.split(\" <=> \")\n    items = utterance_data.split()\n    words = [item.rsplit(':', 1)[0] for item in items]\n    word_labels = [item.rsplit(':', 1)[1] for item in items]\n    return {\n        'intent_label': intent_label,\n        'words': \" \".join(words),\n        'words_label': \" \".join(word_labels),\n        'length': len(words)\n    }","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:03:58.176823Z","iopub.execute_input":"2021-08-27T06:03:58.177243Z","iopub.status.idle":"2021-08-27T06:03:58.1888Z","shell.execute_reply.started":"2021-08-27T06:03:58.177193Z","shell.execute_reply":"2021-08-27T06:03:58.18466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parse_line(lines_train[0])","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:03:58.191407Z","iopub.execute_input":"2021-08-27T06:03:58.191751Z","iopub.status.idle":"2021-08-27T06:03:58.204654Z","shell.execute_reply.started":"2021-08-27T06:03:58.191721Z","shell.execute_reply":"2021-08-27T06:03:58.203554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(Path('vocab.intent').read_text('utf-8'))","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:03:58.20689Z","iopub.execute_input":"2021-08-27T06:03:58.207263Z","iopub.status.idle":"2021-08-27T06:03:58.220333Z","shell.execute_reply.started":"2021-08-27T06:03:58.207223Z","shell.execute_reply":"2021-08-27T06:03:58.219216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(Path('vocab.slot').read_text('utf-8'))","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:03:58.22267Z","iopub.execute_input":"2021-08-27T06:03:58.223248Z","iopub.status.idle":"2021-08-27T06:03:58.231327Z","shell.execute_reply.started":"2021-08-27T06:03:58.223202Z","shell.execute_reply":"2021-08-27T06:03:58.229746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parsed = [parse_line(line) for line in lines_train]\ndf_train = pd.DataFrame([p for p in parsed if p is not None])","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:03:58.233564Z","iopub.execute_input":"2021-08-27T06:03:58.23464Z","iopub.status.idle":"2021-08-27T06:03:58.325707Z","shell.execute_reply.started":"2021-08-27T06:03:58.234592Z","shell.execute_reply":"2021-08-27T06:03:58.324496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print some lines of the training set\ndf_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:03:58.327338Z","iopub.execute_input":"2021-08-27T06:03:58.327796Z","iopub.status.idle":"2021-08-27T06:03:58.35019Z","shell.execute_reply.started":"2021-08-27T06:03:58.327738Z","shell.execute_reply":"2021-08-27T06:03:58.348415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count the number of lines by intent label\ndf_train.intent_label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:03:58.352034Z","iopub.execute_input":"2021-08-27T06:03:58.352468Z","iopub.status.idle":"2021-08-27T06:03:58.371223Z","shell.execute_reply.started":"2021-08-27T06:03:58.352425Z","shell.execute_reply":"2021-08-27T06:03:58.369524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Histogram of sentence lengths\ndf_train.hist('length', bins=30)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:03:58.373359Z","iopub.execute_input":"2021-08-27T06:03:58.373954Z","iopub.status.idle":"2021-08-27T06:03:58.671161Z","shell.execute_reply.started":"2021-08-27T06:03:58.373908Z","shell.execute_reply":"2021-08-27T06:03:58.670072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get validation and test set\nlines_validation = Path('valid').read_text('utf-8').strip().splitlines()\nlines_test = Path('test').read_text('utf-8').strip().splitlines()\n\ndf_validation = pd.DataFrame([parse_line(line) for line in lines_validation])\ndf_test = pd.DataFrame([parse_line(line) for line in lines_test])","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:03:58.67288Z","iopub.execute_input":"2021-08-27T06:03:58.673394Z","iopub.status.idle":"2021-08-27T06:03:58.712635Z","shell.execute_reply.started":"2021-08-27T06:03:58.673321Z","shell.execute_reply":"2021-08-27T06:03:58.711708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Intent classification (sentence level)\n\nLet's ignore the slot filling task for now and let's try to build a sentence level classifier by fine-tuning a pre-trained Transformer-based model using the `huggingface/transformers` package that provides both Tensorflow/Keras and Pytorch APIs.\n\n### The BERT tokenizer\n\nFirst let's load a pre-trained tokenizer and test it on a test sentence from the training set.","metadata":{}},{"cell_type":"code","source":"model_name = 'google/mobilebert-uncased'\ntokenizer = BertTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:03:58.714153Z","iopub.execute_input":"2021-08-27T06:03:58.714726Z","iopub.status.idle":"2021-08-27T06:04:01.419383Z","shell.execute_reply.started":"2021-08-27T06:03:58.714597Z","shell.execute_reply":"2021-08-27T06:04:01.418375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"first_sentence = df_train.iloc[0]['words']\nprint(first_sentence)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:01.421322Z","iopub.execute_input":"2021-08-27T06:04:01.421905Z","iopub.status.idle":"2021-08-27T06:04:01.430797Z","shell.execute_reply.started":"2021-08-27T06:04:01.421856Z","shell.execute_reply":"2021-08-27T06:04:01.429417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.tokenize(first_sentence)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:01.433649Z","iopub.execute_input":"2021-08-27T06:04:01.434314Z","iopub.status.idle":"2021-08-27T06:04:01.443656Z","shell.execute_reply.started":"2021-08-27T06:04:01.434265Z","shell.execute_reply":"2021-08-27T06:04:01.442227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Notive that BERT uses subword tokens. So the length of the tokenized sentence is likely to be larger than the number of words in the sentence. It is particularly interesting to use subword tokenization sentence for general purpose language models such as BERT because it should be possible to generalize the model and then to fine-tuned it to be a specialized one.\n\nEach token string is mapped to a unique integer id that makes it fast to lookup the right column in the input layer token embedding.","metadata":{}},{"cell_type":"code","source":"# Encode sentence to id\ntokenizer.encode(first_sentence)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:01.44641Z","iopub.execute_input":"2021-08-27T06:04:01.446941Z","iopub.status.idle":"2021-08-27T06:04:01.457434Z","shell.execute_reply.started":"2021-08-27T06:04:01.446894Z","shell.execute_reply":"2021-08-27T06:04:01.456111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Do the inverse operation\ntokenizer.decode(tokenizer.encode(first_sentence))","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:01.459868Z","iopub.execute_input":"2021-08-27T06:04:01.460533Z","iopub.status.idle":"2021-08-27T06:04:01.470363Z","shell.execute_reply.started":"2021-08-27T06:04:01.460487Z","shell.execute_reply":"2021-08-27T06:04:01.468507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Remarks:\n* The first token `[CLS]` is used by the pre-training task for sequence classification.\n* The last token `[SEP]` is a separator for the pre-training task that classifies if a pair of sentences are consecutive in a corpus or not (next sentence prediction).\n* Here, we want to use BERT to compute a representation of a single voice command at a time.\n* We could reuse the representation of the `[CLS]` token for sequence classification.\n* Alternatively, we can pool the representations of all the tokens of the voice command (*e.g.* global average) and use that as the input of the final sequence classification layer.","metadata":{}},{"cell_type":"code","source":"train_sequence_lengths = [len(tokenizer.encode(text))\n                          for text in df_train['words']]\nplt.hist(train_sequence_lengths, bins=30)\nplt.title(f'Max sequence length: {max(train_sequence_lengths)}')\nplt.xlabel('Length')\nplt.ylabel('Count')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:01.472459Z","iopub.execute_input":"2021-08-27T06:04:01.473185Z","iopub.status.idle":"2021-08-27T06:04:03.935598Z","shell.execute_reply.started":"2021-08-27T06:04:01.473128Z","shell.execute_reply":"2021-08-27T06:04:03.934506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To perform transfer learning, we will need to work with padded sequences. So, they all have the same sizes. The above histograms, shows that after tokenization, $43$ tokens are enough to represent all the voice commands in the training set.\n\nThe mapping can be introspected in the `tokenizer.vocab` attribute.","metadata":{}},{"cell_type":"code","source":"print(f'Vocabulary size: {tokenizer.vocab_size} words.')","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:03.937135Z","iopub.execute_input":"2021-08-27T06:04:03.937748Z","iopub.status.idle":"2021-08-27T06:04:03.944513Z","shell.execute_reply.started":"2021-08-27T06:04:03.937673Z","shell.execute_reply":"2021-08-27T06:04:03.943058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the items in BERT\nbert_vocab_items = list(tokenizer.vocab.items())","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:03.946949Z","iopub.execute_input":"2021-08-27T06:04:03.947722Z","iopub.status.idle":"2021-08-27T06:04:03.964876Z","shell.execute_reply.started":"2021-08-27T06:04:03.947679Z","shell.execute_reply":"2021-08-27T06:04:03.963552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print some examples of items\nbert_vocab_items[250:260]","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:03.966535Z","iopub.execute_input":"2021-08-27T06:04:03.967252Z","iopub.status.idle":"2021-08-27T06:04:03.98208Z","shell.execute_reply.started":"2021-08-27T06:04:03.967197Z","shell.execute_reply":"2021-08-27T06:04:03.980641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encode_dataset(tokenizer, text_sequences, max_length):\n    token_ids = np.zeros(shape=(len(text_sequences), max_length),\n                         dtype=np.int32)\n    for i, text_sequence in enumerate(text_sequences):\n        encoded = tokenizer.encode(text_sequence)\n        token_ids[i, 0:len(encoded)] = encoded\n    attention_masks = (token_ids != 0).astype(np.int32)\n    \n    return {'input_ids': token_ids, 'attention_masks': attention_masks}","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:03.984752Z","iopub.execute_input":"2021-08-27T06:04:03.98511Z","iopub.status.idle":"2021-08-27T06:04:03.995589Z","shell.execute_reply.started":"2021-08-27T06:04:03.985081Z","shell.execute_reply":"2021-08-27T06:04:03.994296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_train = encode_dataset(tokenizer, df_train['words'], 45)\nencoded_validation = encode_dataset(tokenizer, df_validation['words'], 45)\nencoded_test = encode_dataset(tokenizer, df_test['words'], 45)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:03.997458Z","iopub.execute_input":"2021-08-27T06:04:03.998094Z","iopub.status.idle":"2021-08-27T06:04:07.004312Z","shell.execute_reply.started":"2021-08-27T06:04:03.998013Z","shell.execute_reply":"2021-08-27T06:04:07.003003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_train['input_ids']","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:07.005808Z","iopub.execute_input":"2021-08-27T06:04:07.006329Z","iopub.status.idle":"2021-08-27T06:04:07.013897Z","shell.execute_reply.started":"2021-08-27T06:04:07.006271Z","shell.execute_reply":"2021-08-27T06:04:07.012507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_train['attention_masks']","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:07.015781Z","iopub.execute_input":"2021-08-27T06:04:07.016539Z","iopub.status.idle":"2021-08-27T06:04:07.030152Z","shell.execute_reply.started":"2021-08-27T06:04:07.01649Z","shell.execute_reply":"2021-08-27T06:04:07.028522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"intent_names = Path('vocab.intent').read_text('utf-8').split()\nintent_map = dict((label, idx) for idx, label in enumerate(intent_names))","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:07.032119Z","iopub.execute_input":"2021-08-27T06:04:07.033118Z","iopub.status.idle":"2021-08-27T06:04:07.040579Z","shell.execute_reply.started":"2021-08-27T06:04:07.033062Z","shell.execute_reply":"2021-08-27T06:04:07.03898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"intent_map","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:07.042764Z","iopub.execute_input":"2021-08-27T06:04:07.043604Z","iopub.status.idle":"2021-08-27T06:04:07.059583Z","shell.execute_reply.started":"2021-08-27T06:04:07.04354Z","shell.execute_reply":"2021-08-27T06:04:07.057744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"intent_train = df_train['intent_label'].map(intent_map).values\nintent_validation = df_validation['intent_label'].map(intent_map).values\nintent_test = df_test['intent_label'].map(intent_map).values","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:07.061674Z","iopub.execute_input":"2021-08-27T06:04:07.062228Z","iopub.status.idle":"2021-08-27T06:04:07.077706Z","shell.execute_reply.started":"2021-08-27T06:04:07.062184Z","shell.execute_reply":"2021-08-27T06:04:07.076214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_bert_model = TFBertModel.from_pretrained('google/mobilebert-uncased')\nbase_bert_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:07.07942Z","iopub.execute_input":"2021-08-27T06:04:07.080017Z","iopub.status.idle":"2021-08-27T06:04:17.982239Z","shell.execute_reply.started":"2021-08-27T06:04:07.079954Z","shell.execute_reply":"2021-08-27T06:04:17.981191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outputs = base_bert_model(encoded_validation)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:17.990979Z","iopub.execute_input":"2021-08-27T06:04:17.991289Z","iopub.status.idle":"2021-08-27T06:04:18.73263Z","shell.execute_reply.started":"2021-08-27T06:04:17.991259Z","shell.execute_reply":"2021-08-27T06:04:18.731258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The first output of the BERT model is a tensor with shape: `(batch_size, seq_len, output_dim)` which computes features for each token in the input sequence.","metadata":{}},{"cell_type":"code","source":"print(f'Shape of the first output of the BERT model: {outputs[0].shape}.')","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:18.734336Z","iopub.execute_input":"2021-08-27T06:04:18.734771Z","iopub.status.idle":"2021-08-27T06:04:18.747347Z","shell.execute_reply.started":"2021-08-27T06:04:18.734714Z","shell.execute_reply":"2021-08-27T06:04:18.746136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The second output of the BERT model is a tensor with shape `(batch_size, output_dim)` which is the vector representation of the special token `[CLS]`. This vector is typically used as a pooled representation for the sequence as a whole. This will be used as the features of our latent classifier.","metadata":{}},{"cell_type":"code","source":"print(f'Shape of the second output of the BERT model: {outputs[1].shape}.')","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:18.749407Z","iopub.execute_input":"2021-08-27T06:04:18.749866Z","iopub.status.idle":"2021-08-27T06:04:18.757631Z","shell.execute_reply.started":"2021-08-27T06:04:18.749819Z","shell.execute_reply":"2021-08-27T06:04:18.755737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's build an train a sequece classification model using to predict the intent class. We will use the `self.bert` pretrained model in the `call` method and only consider the pooled features (ignore the token-wise features for now).","metadata":{}},{"cell_type":"code","source":"# Define IntentClassification model\nclass IntentClassificationModel(tf.keras.Model):\n    def __init__(self, intent_num_labels=None,\n                 model_name='google/mobilebert-uncased',\n                 dropout_prob=0.1):\n        super().__init__(name='joint_intent_slot')\n        # Let's preload the pretrained model BERT in the constructor\n        # of our classifier model.\n        self.bert = TFBertModel.from_pretrained(model_name)\n        self.dropout = Dropout(dropout_prob)\n        \n        # Define a (Dense) classification layer to compute for each\n        # sequence in a batch of samples. The number of output classes\n        # is given by the intent_num_labels parameter.\n        # Use the default linear activation (no softmax) to compute\n        # logits. The softmax normalization will be computed in the\n        # loss function instead of the model itself.\n        self.intent_classifier = Dense(intent_num_labels)\n        \n    def call(self, inputs, **kwargs):\n        # Use the pretrained model to extract features from our\n        # encoded inputs.\n        sequence_output, pooled_output = self.bert(inputs, **kwargs)\n        \n        # The second output of the main BERT layer has shape:\n        # (batch_size, output_dim) and gives a \"pooled\" representation\n        # for the full sequence from the hidden state that corresponds\n        # to the \"[CLS]\" token.\n        pooled_output = self.dropout(pooled_output, training=kwargs.get('training', False))\n        \n        # Use the classifier layer to compute the logits from the\n        # pooled features.\n        intent_logits = self.intent_classifier(pooled_output)\n        return intent_logits","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:18.759619Z","iopub.execute_input":"2021-08-27T06:04:18.760269Z","iopub.status.idle":"2021-08-27T06:04:18.77455Z","shell.execute_reply.started":"2021-08-27T06:04:18.760224Z","shell.execute_reply":"2021-08-27T06:04:18.772919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%timeit\n# Build the model\nintent_model = IntentClassificationModel(intent_num_labels=len(intent_map))\n\nintent_model.compile(optimizer=Adam(learning_rate=3e-5, epsilon=1e-08),\n                     loss=SparseCategoricalCrossentropy(from_logits=True),\n                     metrics=[SparseCategoricalAccuracy('accuracy')])","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:18.776538Z","iopub.execute_input":"2021-08-27T06:04:18.777237Z","iopub.status.idle":"2021-08-27T06:04:42.246231Z","shell.execute_reply.started":"2021-08-27T06:04:18.777192Z","shell.execute_reply":"2021-08-27T06:04:42.244812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\n#history = intent_model.fit(encoded_train, intent_train,\n#                           epochs=2, batch_size=32,\n#                           validation_data=(encoded_validation, intent_validation))","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:42.248093Z","iopub.execute_input":"2021-08-27T06:04:42.248781Z","iopub.status.idle":"2021-08-27T06:04:42.253714Z","shell.execute_reply.started":"2021-08-27T06:04:42.248732Z","shell.execute_reply":"2021-08-27T06:04:42.252464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def classify(text, tokenizerzer, model, intent_names):\n    inputs = tf.constant(tokenizer.encode(text))[None, :] # Batch size = 1\n    class_id = model(inputs).numpy().argmax(axis=1)[0]\n    return intent_names[class_id]","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:42.255355Z","iopub.execute_input":"2021-08-27T06:04:42.256062Z","iopub.status.idle":"2021-08-27T06:04:42.486662Z","shell.execute_reply.started":"2021-08-27T06:04:42.255983Z","shell.execute_reply":"2021-08-27T06:04:42.485123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example of classification\n#classify('Which restaurant you would recommend',\n   #      tokenizer, intent_model, intent_names)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:42.488664Z","iopub.execute_input":"2021-08-27T06:04:42.48936Z","iopub.status.idle":"2021-08-27T06:04:42.499278Z","shell.execute_reply.started":"2021-08-27T06:04:42.48931Z","shell.execute_reply":"2021-08-27T06:04:42.497795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"slot_names = [\"[PAD]\"]\nslot_names += Path('vocab.slot').read_text('utf-8').strip().splitlines()\n\nslot_map = {}\nfor label in slot_names:\n    slot_map[label] = len(slot_map)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:42.501813Z","iopub.execute_input":"2021-08-27T06:04:42.502302Z","iopub.status.idle":"2021-08-27T06:04:42.512683Z","shell.execute_reply.started":"2021-08-27T06:04:42.50227Z","shell.execute_reply":"2021-08-27T06:04:42.511563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encode_token_labels(text_sequences, slot_names, tokenizer, slot_map, max_length):\n    encoded = np.zeros(shape=(len(text_sequences), max_length), dtype=np.int32)\n    for i, (text_sequence, word_labels) in enumerate(\n            zip(text_sequences, slot_names)):\n        encoded_labels = []\n        for word, word_label in zip(text_sequence.split(), word_labels.split()):\n            tokens = tokenizer.tokenize(word)\n            encoded_labels.append(slot_map[word_label])\n            expand_label = word_label.replace(\"B-\", \"I-\")\n            if not expand_label in slot_map:\n                expand_label = word_label\n            encoded_labels.extend([slot_map[expand_label]] * (len(tokens) - 1))\n        encoded[i, 1:len(encoded_labels) + 1] = encoded_labels\n    return encoded","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:42.515235Z","iopub.execute_input":"2021-08-27T06:04:42.516074Z","iopub.status.idle":"2021-08-27T06:04:42.528232Z","shell.execute_reply.started":"2021-08-27T06:04:42.515987Z","shell.execute_reply":"2021-08-27T06:04:42.526489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"slot_train = encode_token_labels(df_train['words'], df_train['words_label'], tokenizer, slot_map, 45)\nslot_validation = encode_token_labels(df_validation['words'], df_validation['words_label'], tokenizer, slot_map, 45)\nslot_test = encode_token_labels(df_test['words'], df_test['words_label'], tokenizer, slot_map, 45)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:42.530485Z","iopub.execute_input":"2021-08-27T06:04:42.531414Z","iopub.status.idle":"2021-08-27T06:04:47.667464Z","shell.execute_reply.started":"2021-08-27T06:04:42.531335Z","shell.execute_reply":"2021-08-27T06:04:47.666306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define JointIntentAndSlotFilling model\nclass JointIntentAndSlotFillingModel(tf.keras.Model):\n\n    def __init__(self, intent_num_labels=None, slot_num_labels=None,\n                 model_name=\"google/mobilebert-uncased\", dropout_prob=0.1):\n        super().__init__(name=\"joint_intent_slot\")\n        self.bert = TFBertModel.from_pretrained(model_name)\n        self.dropout = Dropout(dropout_prob)\n        self.intent_classifier = Dense(intent_num_labels,\n                                       name=\"intent_classifier\")\n        self.slot_classifier = Dense(slot_num_labels,\n                                     name=\"slot_classifier\")\n\n    def call(self, inputs, **kwargs):\n        sequence_output, pooled_output = self.bert(inputs, **kwargs)\n\n        # The first output of the main BERT layer has shape:\n        # (batch_size, max_length, output_dim)\n        sequence_output = self.dropout(sequence_output,\n                                       training=kwargs.get(\"training\", False))\n        slot_logits = self.slot_classifier(sequence_output)\n\n        # The second output of the main BERT layer has shape:\n        # (batch_size, output_dim)\n        # and gives a \"pooled\" representation for the full sequence from the\n        # hidden state that corresponds to the \"[CLS]\" token.\n        pooled_output = self.dropout(pooled_output,\n                                     training=kwargs.get(\"training\", False))\n        intent_logits = self.intent_classifier(pooled_output)\n\n        return slot_logits, intent_logits","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:47.669305Z","iopub.execute_input":"2021-08-27T06:04:47.669766Z","iopub.status.idle":"2021-08-27T06:04:47.682418Z","shell.execute_reply.started":"2021-08-27T06:04:47.669685Z","shell.execute_reply":"2021-08-27T06:04:47.681087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\njoint_model = JointIntentAndSlotFillingModel(\n    intent_num_labels=len(intent_map), slot_num_labels=len(slot_map))\n\n# Define one classification loss for each output:\nopt = Adam(learning_rate=3e-5, epsilon=1e-08)\nlosses = [SparseCategoricalCrossentropy(from_logits=True),\n          SparseCategoricalCrossentropy(from_logits=True)]\nmetrics = [SparseCategoricalAccuracy('accuracy')]\njoint_model.compile(optimizer=opt, loss=losses, metrics=metrics)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:47.684428Z","iopub.execute_input":"2021-08-27T06:04:47.685235Z","iopub.status.idle":"2021-08-27T06:04:50.953185Z","shell.execute_reply.started":"2021-08-27T06:04:47.685188Z","shell.execute_reply":"2021-08-27T06:04:50.95204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nhistory = joint_model.fit(\n    encoded_train, (slot_train, intent_train),\n    validation_data=(encoded_validation, (slot_validation, intent_validation)),\n    epochs=2, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:04:50.95481Z","iopub.execute_input":"2021-08-27T06:04:50.955279Z","iopub.status.idle":"2021-08-27T06:06:57.979564Z","shell.execute_reply.started":"2021-08-27T06:04:50.955232Z","shell.execute_reply":"2021-08-27T06:06:57.978569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"joint_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:06:57.983282Z","iopub.execute_input":"2021-08-27T06:06:57.983633Z","iopub.status.idle":"2021-08-27T06:06:58.043918Z","shell.execute_reply.started":"2021-08-27T06:06:57.983596Z","shell.execute_reply":"2021-08-27T06:06:58.043079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_predictions(text, tokenizer, model, intent_names, slot_names):\n    inputs = tf.constant(tokenizer.encode(text))[None, :]  # batch_size = 1\n    outputs = model(inputs)\n    slot_logits, intent_logits = outputs\n    slot_ids = slot_logits.numpy().argmax(axis=-1)[0, 1:-1]\n    intent_id = intent_logits.numpy().argmax(axis=-1)[0]\n    print(\"## Intent:\", intent_names[intent_id])\n    print(\"## Slots:\")\n    for token, slot_id in zip(tokenizer.tokenize(text), slot_ids):\n        print(f\"{token:>10} : {slot_names[slot_id]}\")","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:06:58.047487Z","iopub.execute_input":"2021-08-27T06:06:58.047832Z","iopub.status.idle":"2021-08-27T06:06:58.059969Z","shell.execute_reply.started":"2021-08-27T06:06:58.047801Z","shell.execute_reply":"2021-08-27T06:06:58.056822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example of classification\nshow_predictions('Will it snow tomorrow in Paris?',\n                 tokenizer, joint_model, intent_names, slot_names)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:06:58.061942Z","iopub.execute_input":"2021-08-27T06:06:58.062587Z","iopub.status.idle":"2021-08-27T06:06:58.390832Z","shell.execute_reply.started":"2021-08-27T06:06:58.062539Z","shell.execute_reply":"2021-08-27T06:06:58.389993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Decoding predictions into structured knowledge\n\nFor completeness, here a minimal functional to naively decode the predicted BIO slot ids and convert it into a structured representation for the detected slots as a Python dictionaries.","metadata":{}},{"cell_type":"code","source":"def decode_predictions(text, tokenizer, intent_names, slot_names,\n                       intent_id, slot_ids):\n    info = {\"intent\": intent_names[intent_id]}\n    collected_slots = {}\n    active_slot_words = []\n    active_slot_name = None\n    for word in text.split():\n        tokens = tokenizer.tokenize(word)\n        current_word_slot_ids = slot_ids[:len(tokens)]\n        slot_ids = slot_ids[len(tokens):]\n        current_word_slot_name = slot_names[current_word_slot_ids[0]]\n        if current_word_slot_name == \"O\":\n            if active_slot_name:\n                collected_slots[active_slot_name] = \" \".join(active_slot_words)\n                active_slot_words = []\n                active_slot_name = None\n        else:\n            # Naive BIO: handling: treat B- and I- the same...\n            new_slot_name = current_word_slot_name[2:]\n            if active_slot_name is None:\n                active_slot_words.append(word)\n                active_slot_name = new_slot_name\n            elif new_slot_name == active_slot_name:\n                active_slot_words.append(word)\n            else:\n                collected_slots[active_slot_name] = \" \".join(active_slot_words)\n                active_slot_words = [word]\n                active_slot_name = new_slot_name\n    if active_slot_name:\n        collected_slots[active_slot_name] = \" \".join(active_slot_words)\n    info[\"slots\"] = collected_slots\n    return info","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:06:58.392927Z","iopub.execute_input":"2021-08-27T06:06:58.393352Z","iopub.status.idle":"2021-08-27T06:06:58.408477Z","shell.execute_reply.started":"2021-08-27T06:06:58.393309Z","shell.execute_reply":"2021-08-27T06:06:58.407444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def nlu(text, tokenizer, model, intent_names, slot_names):\n    inputs = tf.constant(tokenizer.encode(text))[None, :]  # batch_size = 1\n    outputs = model(inputs)\n    slot_logits, intent_logits = outputs\n    slot_ids = slot_logits.numpy().argmax(axis=-1)[0, 1:-1]\n    intent_id = intent_logits.numpy().argmax(axis=-1)[0]\n\n    return decode_predictions(text, tokenizer, intent_names, slot_names,\n                              intent_id, slot_ids)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:06:58.410824Z","iopub.execute_input":"2021-08-27T06:06:58.411343Z","iopub.status.idle":"2021-08-27T06:06:58.425837Z","shell.execute_reply.started":"2021-08-27T06:06:58.411298Z","shell.execute_reply":"2021-08-27T06:06:58.424888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nlu('I want some chinese food',\n                 tokenizer, joint_model, intent_names, slot_names)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:06:58.427545Z","iopub.execute_input":"2021-08-27T06:06:58.428068Z","iopub.status.idle":"2021-08-27T06:06:58.747708Z","shell.execute_reply.started":"2021-08-27T06:06:58.428007Z","shell.execute_reply":"2021-08-27T06:06:58.746937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nlu('tokyo restaurant in the north of town',\n    tokenizer, joint_model, intent_names, slot_names)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:06:58.751069Z","iopub.execute_input":"2021-08-27T06:06:58.75149Z","iopub.status.idle":"2021-08-27T06:06:59.068393Z","shell.execute_reply.started":"2021-08-27T06:06:58.751458Z","shell.execute_reply":"2021-08-27T06:06:59.06744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pre Handling the Input from DST2\n","metadata":{}},{"cell_type":"markdown","source":"Get a glance at the dataset, output is what agent speak while input is what human speak\n","metadata":{}},{"cell_type":"code","source":"dst2csv = '../input/modified-dst2/data.csv'\ndst2data = pd.read_csv(dst2csv)\n\ndst2data.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:06:59.070452Z","iopub.execute_input":"2021-08-27T06:06:59.070731Z","iopub.status.idle":"2021-08-27T06:06:59.148164Z","shell.execute_reply.started":"2021-08-27T06:06:59.070703Z","shell.execute_reply":"2021-08-27T06:06:59.146667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentiment_model = \"cardiffnlp/twitter-roberta-base-sentiment\"\nsentiment_classifier = pipeline('sentiment-analysis',model=sentiment_model,tokenizer=AutoTokenizer.from_pretrained(sentiment_model))\n","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:06:59.150316Z","iopub.execute_input":"2021-08-27T06:06:59.150806Z","iopub.status.idle":"2021-08-27T06:07:46.325627Z","shell.execute_reply.started":"2021-08-27T06:06:59.150761Z","shell.execute_reply":"2021-08-27T06:07:46.324529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport copy\n\nimport math\n\nfrom scipy import spatial\n\n\n\ndef cosine_similarity(a,b):\n    cosine_similarity = 1 - float(spatial.distance.cosine(a, b))\n    return cosine_similarity\n\n\ndef countDictValue(dict1):\n    count = 0\n    for key,value in dict1.items():\n        if type(value) == list:\n            count+=len(value)\n        else :\n            count +=1\n    return count\n\n\ndef getSentimentPoints(sentense):\n    \n    result = sentiment_classifier(sentense)[0]\n    if(\"1\" in result[\"label\"]):\n        return 0\n    elif(\"0\" in result[\"label\"]):\n        return -1\n    else:\n        return 1\n\ndef mergeDict(dict1,dict2):\n    newDict = dict1\n    for key,value in dict2.items():\n        if key not in newDict:\n            newDict[key] = value\n        else :\n            exist_value = newDict[key]\n            # exist value can be list or normal variable\n            if type(exist_value) == list:\n                if value in exist_value:\n                    pass\n                else:\n                    newDict[key].append(value)\n            elif exist_value != value:\n                newDict[key]=[exist_value,value]\n    return newDict\n    \n\n\n    \n\nclass dialog :\n    def __init__(self,id,input,output):\n        self.input = input\n        self.output = output\n        self.id = id\n        self.buildIndex()\n        self.calculateSentiment()\n        self.calculateSlots()\n    \n    # compare with previous 2 sentenses    \n    def getSimilarity(self,index):\n        input_similar_1 = 0\n        output_similar_1 = 0\n        input_similar_2 = 0\n        output_similar_2 = 0\n        output_vect = self.round_vector[index][0]\n        input_vect = self.round_vector[index][1]\n        if(index > 0):\n            output_vect_1 = self.round_vector[index-1][0]\n            input_vect_1 = self.round_vector[index-1][1]\n            input_similar_1 = cosine_similarity(input_vect,input_vect_1)\n            output_similar_1 = cosine_similarity(output_vect,output_vect_1)\n        if(index>1):\n            output_vect_2 = self.round_vector[index-2][0]\n            input_vect_2 = self.round_vector[index-2][1]\n            input_similar_2 = cosine_similarity(input_vect,input_vect_2)\n            output_similar_2 = cosine_similarity(output_vect,output_vect_2)\n        return input_similar_1,output_similar_1,input_similar_2,output_similar_2\n    \n    def buildIndex(self):\n        output_sentenses = self.output.split(\"|\")\n        input_sentenses = self.input.split(\"|\")\n        self.round = {}\n        self.round_vector = {}\n        outside = 0\n        inside = 0\n        for sent in output_sentenses:\n            if sent !=\"\":\n                outside+=1\n        for sent in input_sentenses:\n            if sent !=\"\":\n                inside+=1\n        self.round_counter = min(outside,inside)\n        for i in range(self.round_counter):\n            if(output_sentenses[i]):\n                self.round[i]=(output_sentenses[i],input_sentenses[i])\n                embed_vector = embed([output_sentenses[i],input_sentenses[i]])\n                self.round_vector[i] = (embed_vector[0].numpy(),embed_vector[1].numpy())\n\n    def calculateSentiment(self):\n        self.sentiment_list=[]\n        for index in range(self.round_counter):\n            output_sent = self.round[index][0]\n            input_sent = self.round[index][1]\n            self.sentiment_list.append((getSentimentPoints(output_sent),getSentimentPoints(input_sent)))\n            \n    def calculateSlots(self):\n        self.overall_slot_list=[]\n        for index in range(self.round_counter):\n            output_sent = self.round[index][0]\n            input_sent = self.round[index][1]\n            output_result = nlu(output_sent,tokenizer, joint_model, intent_names, slot_names)\n            input_result = nlu(output_sent,tokenizer, joint_model, intent_names, slot_names)\n            mergedDict = mergeDict(output_result[\"slots\"],input_result[\"slots\"])\n            if index == 0 :\n                self.overall_slot_list.append(mergedDict)\n            else :\n                oldDict = self.overall_slot_list[index-1]\n                currentDict = mergeDict(oldDict,mergedDict)\n                self.overall_slot_list.append(currentDict.copy())\n\n                               \n               \n    def avgSentiment(self,index):\n        if (index ==0):\n            return 0,0\n        else:\n            inputList=[]\n            outputList=[]\n            for x,y in self.sentiment_list[0:index]:\n                outputList.append(x)\n                inputList.append(y)\n            return sum(outputList)/len(outputList),sum(inputList)/len(inputList)\n        \n        \n        \n    def getSetiments(self,index):\n        output_sentiment,input_sentiment = self.sentiment_list[index]\n        output_sentiment_1 = 0\n        input_sentiment_1 = 0\n        output_sentiment_2 = 0\n        input_sentiment_2 = 0\n        if (index>0):\n            output_sentiment_1,input_sentiment_1 = self.sentiment_list[index-1]\n        if (index>1):\n            output_sentiment_2,input_sentiment_2 = self.sentiment_list[index-2]           \n        \n        return output_sentiment,input_sentiment,output_sentiment_1,input_sentiment_1,output_sentiment_2,input_sentiment_2 \n    \n    def getSlotNumbers(self,index):\n        extraSlotNum = 0\n        extraSlotNum_1 = 0\n        extraSlotNum_2 = 0 \n        currentDict = self.overall_slot_list[index]\n        if(index>0):\n            historyDict = self.overall_slot_list[index-1]\n            extraSlotNum = countDictValue(currentDict) - countDictValue(historyDict)\n        if(index>1):\n            historyDict_1 = self.overall_slot_list[index-2]\n            extraSlotNum_1 = countDictValue(historyDict) - countDictValue(historyDict_1)    \n        if(index>2):\n            historyDict_2 = self.overall_slot_list[index-3]\n            extraSlotNum_2 = countDictValue(historyDict_1) - countDictValue(historyDict_2)         \n        return extraSlotNum,extraSlotNum_1,extraSlotNum_2\n    \n    \n    \n\n                               \n    # return points later on for SVM/OCNN      \n    # return current output/ionput motion points,props,slots number for input/output,and its props.\n    def getMetrix(self,index):\n        identity = self.id + \"|\" + str(index)\n        if index > self.round_counter:\n            print(\"failed:\",index)\n            return None\n        else:\n            output_avg_sentiment,input_avg_sentiment=self.avgSentiment(index)\n            currentDict = self.overall_slot_list[index]\n            output_sentiment,input_sentiment,output_sentiment_1,input_sentiment_1,output_sentiment_2,input_sentiment_2 = self.getSetiments(index)\n            extraSlotNum,extraSlotNum_1,extraSlotNum_2 = self.getSlotNumbers(index)\n            input_similar_1,output_similar_1,input_similar_2,output_similar_2 = self.getSimilarity(index)\n            # index is the actual index-1 time size of the history\n            avgSlotNum = countDictValue(currentDict)/(index+1)\n            return [identity,output_sentiment,input_sentiment,output_sentiment_1,input_sentiment_1,output_sentiment_2,input_sentiment_2,output_avg_sentiment,input_avg_sentiment,extraSlotNum,extraSlotNum_1,extraSlotNum_2,avgSlotNum,input_similar_1,output_similar_1,input_similar_2,output_similar_2]\n    \n     \n\n\n\n\n\n\nfor index, row in dst2data.iterrows():\n    if(index==0):\n        record = dialog(row[\"id\"],row[\"input\"],row[\"output\"])\n        if record.round_counter<2 :\n            pass\n        else :\n            a = datetime.datetime.now()\n            for index in range(1,record.round_counter):\n                output = record.getMetrix(index)\n                print(output)\n\n            b = datetime.datetime.now()\n            print(b-a)\n            \n    \n\n    \n\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:11:54.907314Z","iopub.execute_input":"2021-08-27T06:11:54.907707Z","iopub.status.idle":"2021-08-27T06:11:59.157589Z","shell.execute_reply.started":"2021-08-27T06:11:54.907676Z","shell.execute_reply":"2021-08-27T06:11:59.156745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = datetime.datetime.now()\ngetSentimentPoints(\"hello world\")  \nb = datetime.datetime.now()\nprint(b-a)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:13:04.703448Z","iopub.execute_input":"2021-08-27T06:13:04.703829Z","iopub.status.idle":"2021-08-27T06:13:04.784222Z","shell.execute_reply.started":"2021-08-27T06:13:04.703783Z","shell.execute_reply":"2021-08-27T06:13:04.782888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = datetime.datetime.now()\nembed([\"hello world\"])  \nnlu('tokyo restaurant in the north of town',\n    tokenizer, joint_model, intent_names, slot_names)\nb = datetime.datetime.now()\nprint(b-a)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:16:43.740658Z","iopub.execute_input":"2021-08-27T06:16:43.741027Z","iopub.status.idle":"2021-08-27T06:16:44.070889Z","shell.execute_reply.started":"2021-08-27T06:16:43.74097Z","shell.execute_reply":"2021-08-27T06:16:44.0698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n\nimport csv\nfrom IPython.display import FileLink\n\nf = open('generated.csv', 'w',newline='', encoding='utf-8')\nwriter = csv.writer(f)\nheader = [\"id\",\"output-sentiment\",\"input-sentiment\",\"output_sentiment_1\",\"input_sentiment_1\",\"output_sentiment_2\",\"input_sentiment_2\",\"output_avg_sentiment\",\"input_avg_sentiment\",\"slot_in_round\",\"slot_in_round_1\",\"slot_in_round_2\",\"avg_slots\",\"input_similar_1\",\"output_similar_1\",\"input_similar_2\",\"output_similar_2\"]\nwriter.writerow(header)\ncount = 0\nfor no,row in dst2data.iterrows():\n    try:\n        record = dialog(row[\"id\"],row[\"input\"],row[\"output\"])\n        # we dont care about the first round, start from second round\n        if record.round_counter <2 :\n            pass\n        elif no in [45,52,50,51,102,146,192,226,229,261,289,298,360,388,416,423,469,501,507]:\n            print(\"ignore id \",row[\"id\"])\n        else :\n            for index in range(1,record.round_counter):\n                output = record.getMetrix(index)\n                writer.writerow(output)\n            count+=1\n            if count>=200:\n                print(\"finished\")\n                break\n    except:\n        print(row[\"id\"])\n            \n            \nf.close()\n    \n","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:07:51.173217Z","iopub.status.idle":"2021-08-27T06:07:51.173699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nf = open('generated_val.csv', 'w',newline='', encoding='utf-8')\nwriter = csv.writer(f)\nheader = [\"id\",\"output-sentiment\",\"input-sentiment\",\"output_avg_sentiment\",\"input_avg_sentiment\",\"slot_in_round\",\"avg_slots\"]\nwriter.writerow(header)\ncount = 0\nfor no,row in dst2data.iterrows():\n    try:\n        record = dialog(row[\"id\"],row[\"input\"],row[\"output\"])\n        # we dont care about the first round, start from second round\n        if record.round_counter <2 :\n            pass\n        elif no<=115:\n            pass\n        elif no in [45,52,50,51,102,146,192,226,229,261,289,298,360,388,416,423,469,501,507]:\n            print(\"ignore id \",row[\"id\"])\n        else :\n            for index in range(1,record.round_counter):\n                output = record.getMetrix(index)\n                writer.writerow(output)\n            count+=1\n            if count>=30:\n                print(\"finished\")\n                break\n    except:\n        print(row[\"id\"])\n            \n            \nf.close()\n'''","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:07:51.175148Z","iopub.status.idle":"2021-08-27T06:07:51.175774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nimport csv\nfrom IPython.display import FileLink\n\ntestdata = pd.read_csv(\"../input/modified-dst2/selected_failed_call.csv\")\n\n\nf = open('generated_test.csv', 'w',newline='', encoding='utf-8')\nwriter = csv.writer(f)\nheader = [\"id\",\"output-sentiment\",\"input-sentiment\",\"output_sentiment_1\",\"input_sentiment_1\",\"output_sentiment_2\",\"input_sentiment_2\",\"output_avg_sentiment\",\"input_avg_sentiment\",\"slot_in_round\",\"slot_in_round_1\",\"slot_in_round_2\",\"avg_slots\",\"input_similar_1\",\"output_similar_1\",\"input_similar_2\",\"output_similar_2\"]\nwriter.writerow(header)\nfor _, row in testdata.iterrows():\n    try:\n        record = dialog(row[\"id\"],row[\"input\"],row[\"output\"])\n        output = record.getMetrix(record.round_counter-1)\n        writer.writerow(output)\n    except:\n        print(row[\"id\"])\n            \n            \nf.close()","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:07:51.176974Z","iopub.status.idle":"2021-08-27T06:07:51.17772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nimport csv\nfrom IPython.display import FileLink\n\ntestdata = pd.read_csv(\"../input/failedcall/failedcall_removed.csv\")\n\n\nf = open('generated_test_extra.csv', 'w',newline='', encoding='utf-8')\nwriter = csv.writer(f)\nheader = [\"id\",\"output-sentiment\",\"input-sentiment\",\"output_sentiment_1\",\"input_sentiment_1\",\"output_sentiment_2\",\"input_sentiment_2\",\"output_avg_sentiment\",\"input_avg_sentiment\",\"slot_in_round\",\"slot_in_round_1\",\"slot_in_round_2\",\"avg_slots\",\"input_similar_1\",\"output_similar_1\",\"input_similar_2\",\"output_similar_2\"]\nwriter.writerow(header)\nfor _, row in testdata.iterrows():\n    try:\n        record = dialog(row[\"id\"],row[\"input\"],row[\"output\"])\n        output = record.getMetrix(record.round_counter-1)\n        writer.writerow(output)\n    except:\n        print(row[\"id\"])\n            \n            \nf.close()","metadata":{"execution":{"iopub.status.busy":"2021-08-27T06:07:51.179186Z","iopub.status.idle":"2021-08-27T06:07:51.180041Z"},"trusted":true},"execution_count":null,"outputs":[]}]}