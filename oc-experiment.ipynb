{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nimport sklearn\nfrom sklearn.metrics import precision_recall_fscore_support, classification_report,confusion_matrix, precision_recall_curve\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn import utils  \nfrom sklearn import svm\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom keras import backend as K\nimport keras\nfrom keras.models import Model\nfrom keras.layers import Dense, Input\nfrom sklearn.model_selection import GridSearchCV\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"origin_data = pd.read_csv(\"../input/processeddst2/generated_v3.csv\")\norigin_data.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Split the ID to identity ID and its round\n","metadata":{}},{"cell_type":"code","source":"origin_data[['call-id', 'round']] = origin_data['id'].str.split('|', 1, expand=True)\ndel origin_data[\"call-id\"]\ndel origin_data[\"id\"]\norigin_data[\"round\"].astype('float32')\norigin_data[\"output-sentiment\"].astype('float32')\norigin_data[\"input-sentiment\"].astype('float32')\norigin_data[\"slot_in_round\"].astype('float32')\norigin_data.head(5)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"failed_data = pd.read_csv(\"../input/processeddst2/generated_test_v3.csv\")\nfailed_data[['call-id', 'round']] = failed_data['id'].str.split('|', 1, expand=True)\n\ndel failed_data[\"call-id\"]\ndel failed_data[\"id\"]\nfailed_data[\"round\"].astype('float32')\nfailed_data[\"output-sentiment\"].astype('float32')\nfailed_data[\"input-sentiment\"].astype('float32')\nfailed_data[\"slot_in_round\"].astype('float32')\nfailed_data.head(5)\nfailed_samples = failed_data.to_numpy(\"float32\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#First Idea is RNN","metadata":{}},{"cell_type":"code","source":"positive_samples = origin_data.to_numpy(\"float32\")\nX =  np.concatenate([positive_samples,failed_samples])\n\nY= [1 for x in range(len(positive_samples))] + [-1 for x in range(len(failed_samples))]\n\nX_train,X_test, Y_train, Y_test = train_test_split(X,Y,stratify=Y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train_transformed = scaler.fit_transform(X_train)\nX_test_transformed = scaler.transform(X_test)\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE \n\nsm = SMOTE(random_state=42)\nX_res, Y_res = sm.fit_resample(X_train_transformed, Y_train)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import NearestCentroid\n\nclf = NearestCentroid()\nclf.fit(X_res,Y_res)\n\nY_pred = clf.predict(X_test_transformed)\n\nprint(classification_report(Y_test,Y_pred))\nprint(confusion_matrix(Y_test,Y_pred))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ntree_para = {'criterion':['gini','entropy'],'max_depth':range(1,20),\"splitter\":[\"best\",\"random\"],\"min_samples_split\":range(2,20),\"max_features\":[\"auto\", \"sqrt\", \"log2\"]}\n\n\nclf = GridSearchCV(DecisionTreeClassifier(class_weight=\"balanced\"), tree_para, cv=5,scoring=\"roc_auc\")\n\n\nclf.fit(X_res,Y_res)\nY_pred = clf.predict(X_test_transformed)\n\nprint(classification_report(Y_test,Y_pred))\nprint(confusion_matrix(Y_test,Y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ROC_AUC:  [[  3   2]\n [  7 275]]\n P=0.3 recall = 0.6\n \n \n f1 :\n P=0.29, recall = 0.4 [[  2   3]\n [  5 277]]\n \n \n precision P0.1 recall 1.0\n \n [[  5   0]\n [ 44 238]]\n \n \n recall: p 0 recall 0\n \n [[  0   5]\n [  7 275]]\n \n \n \n \n Using SMOTE\n \n ------------------------------------------\n Not Using Smote\n \n recall: P 0.25 recall 0.2\n [[  1   4]\n [  3 279]]\n \n \n precision: P 0.09,recall 0.8 [[  4   1]\n [ 42 240]]\n \n f1: P 0.31 R 0.8 [[  4   1]\n [  9 273]]\n \n \n \nroc_auc P 0.1 R 0.8\n\n \n ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nclf = RandomForestClassifier()\n\nclf.fit(X_res, Y_res)\nY_pred = clf.predict(X_test_transformed)\n\nprint(classification_report(Y_test,Y_pred))\nprint(confusion_matrix(Y_test,Y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ntest_data = pd.read_csv(\"../input/processeddst2/generated_val_v2.csv\")\ntest_data[['call-id', 'round']] = test_data['id'].str.split('|', 1, expand=True)\ndel test_data[\"call-id\"]\ndel test_data[\"id\"]\ntest_data[\"round\"].astype('float32')\ntest_data[\"output-sentiment\"].astype('float32')\ntest_data[\"input-sentiment\"].astype('float32')\ntest_data[\"slot_in_round\"].astype('float32')\ntest_data.head(5)\ntest_data = test_data.to_numpy(\"float32\")\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\n\n\nboost_classifier = {'n_estimators':range(1,10),\"algorithm\":[\"SAMME\",\"SAMME.R\"]}\n\n\nclf = GridSearchCV(AdaBoostClassifier(), boost_classifier, cv=5,scoring=\"recall\")\n\n\nclf.fit(X_res, Y_res)\nY_pred = clf.predict(X_test_transformed)\n\nprint(classification_report(Y_test,Y_pred))\nprint(confusion_matrix(Y_test,Y_pred))\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nearly_stop = keras.callbacks.EarlyStopping(monitor=\"loss\", min_delta=0, patience=5, mode=\"auto\")\n\n\n# this time origin_data is the training data\ninput_dim=17\n\ndef inner_tanh(x):\n    k = 3\n    N = 4\n    return 1/2 + 1/(2*(k-1)) * sum(K.tanh(x- (j/N)) for j in range(1, N-1))\n\n\ndef get_RNNmodel():\n    inp = Input(shape=(input_dim, ))\n    x = Dense(input_dim//2, activation=\"tanh\")(inp)\n    x = Dense(input_dim//4, activation=inner_tanh)(x)\n    x = Dense(input_dim//2, activation=\"tanh\")(x)\n    outp = Dense(input_dim, activation=\"sigmoid\")(x)\n    \n    model = Model(inputs=inp, outputs=outp)\n    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n    return model\n\n\nRNNmodel = get_RNNmodel()\nRNNmodel.summary()\n\n\n\nhist = RNNmodel.fit(positive_samples, positive_samples, epochs=1000, callbacks=[early_stop], verbose=0)\nfinal_loss = hist.history[\"loss\"][-1]\nfinal_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build AE solution\n\ndef get_AEmodel():\n    inp = Input(shape=(input_dim, ))\n    encoded = Dense(input_dim//2, activation=\"relu\")(inp)\n    decoded = Dense(input_dim, activation=\"sigmoid\")(encoded)\n    \n    model = Model(inputs=inp, outputs=decoded)\n    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n    return model\n\n\nAEmodel = get_AEmodel()\nAEmodel.summary()\n\nhist = AEmodel.fit(positive_samples, positive_samples, epochs=1000, callbacks=[early_stop], verbose=0)\nfinal_loss = hist.history[\"loss\"][-1]\nfinal_loss\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#SVM model","metadata":{}},{"cell_type":"code","source":"success_numbers=len(test_data)\nfailed_numbers=len(failed_samples)\noutliers_fraction =failed_numbers/success_numbers\nSVMmodel = svm.OneClassSVM(kernel='rbf', nu=outliers_fraction,gamma=0.1)\nSVMmodel.fit(train_data)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test Under OneClassSVM\n\n\nX =  np.concatenate([test_data,failed_samples])\nY_true = [1 for x in range(len(test_data))] + [-1 for x in range(failed_numbers)]\n\n\nY_pred = SVMmodel.predict(X)\n\nfrom sklearn.metrics import confusion_matrix,roc_auc_score,classification_report\n\nconfusion_matrix(Y_true,Y_pred)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_auc_score(Y_true,Y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(Y_true,Y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict on  RNN\n\nfrom collections import defaultdict\nfrom sklearn.metrics import mean_squared_error\n\n\ndef analyze_outlier(df):\n    sorted_df = df.sort_values(by=['OF'], ascending=False)\n    first20 = sorted_df.head(20)\n    first20_Y = first20['Y'].tolist()\n    first20_0count = first20_Y.count(0)\n    first20_accuracy = (first20_0count / 30) * 100\n    \n    print (\"Within the top 20 ranked cases (ranked according to the Outlier Factor), {} of the malignant cases (the outliers), comprising {}% of all malignant cases, were identified.\".format(first20_0count, first20_accuracy))\n\n\ndef calculate_outlier_factor(X, Y, pred):\n    outlier_factors = defaultdict(dict)\n    for i in range(X.shape[0]):\n        outlier_factors[i][\"OF\"] = mean_squared_error(X[i], pred[i])\n        outlier_factors[i][\"Y\"] = Y[i]\n    return outlier_factors\n\n\n\nY_pred = RNNmodel.predict(X)\noutlier_factors = calculate_outlier_factor(X, Y_true, Y_pred)\ndf = pd.DataFrame.from_dict(outlier_factors, orient=\"index\")\nanalyze_outlier(df)\n    \n\n    \n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nY_pred = AEmodel.predict(X)\noutlier_factors = calculate_outlier_factor(X, Y_true, Y_pred)\ndf = pd.DataFrame.from_dict(outlier_factors, orient=\"index\")\nanalyze_outlier(df)\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# IsolationForest\n\nfrom sklearn.ensemble import IsolationForest\n\n\nISOModel = IsolationForest()\nISOModel.fit(train_data)\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred = ISOModel.predict(X)\nprint(classification_report(Y_true,Y_pred))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Local Outlier Factor\n\nfrom sklearn.neighbors import LocalOutlierFactor \n\nLOF =  LocalOutlierFactor(n_neighbors=5,novelty=True)\nLOF.fit(train_data)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred = LOF.predict(X)\nprint(classification_report(Y_true,Y_pred))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}